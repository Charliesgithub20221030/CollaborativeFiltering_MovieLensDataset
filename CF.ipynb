{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "romance-multiple",
   "metadata": {},
   "source": [
    "\n",
    "## Concept\n",
    "- sampling user-item to form pairs: \n",
    "    [U1,I3]: T\n",
    "    [U2,I9]: F\n",
    "    ...\n",
    "- architecture:\n",
    "    user-embedding->\n",
    "    item-embedding-> aggregation -> T/F\n",
    "    \n",
    "- embedding layer: no need to one-hot processing\n",
    "    \n",
    "- U/I be one-hot, but sometimes can has attributes    \n",
    "\n",
    "### architecture (pairwise model) example: \n",
    "CBOW, Rank , skip-gram ...\n",
    "\n",
    "### advantage:\n",
    "- can skip null value\n",
    "\n",
    "### disadvantage:\n",
    "- dataset become very large\n",
    "\n",
    "\n",
    "### Content based:\n",
    "e.g. use statistics dattribute \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aquatic-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding , Input , Activation , Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pickle ,  gc \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aboriginal-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fn):\n",
    "    \"\"\"\n",
    "    user id | item id | rating | timestamp. \n",
    "    \"\"\"\n",
    "    with open(fn , 'r' , encoding = 'utf-8') as f:\n",
    "        data = f.read()\n",
    "    data=[row.split('\\t') for row in data.split(\"\\n\") if row != '']\n",
    "    x_u = [int(row[0]) for row in data]\n",
    "    x_i = [int(row[1]) for row in data]\n",
    "    x = [np.array(x_u), np.array(x_i)]\n",
    "    y = np.array([float(row[2])-1 for row in data])\n",
    "    return x,y\n",
    "\n",
    "def meta(x,y,title='train'):\n",
    "    user = set(x[0])\n",
    "    item = set(x[1])\n",
    "    y = set([int(row) for row in y])\n",
    "    print(f\"\"\"\n",
    "    type: {title} \n",
    "=============================\n",
    "num user: {len(user)}\n",
    "max userId: {max(user)}\n",
    "\n",
    "num item: {len(item)}\n",
    "max itemId: {max(item)}\n",
    "min itemId: {min(item)}\n",
    "    \"\"\")\n",
    "    print('y set: ', y)\n",
    "    return max(user) , max(item) , max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "received-replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    type: train \n",
      "=============================\n",
      "num user: 943\n",
      "max userId: 943\n",
      "\n",
      "num item: 1650\n",
      "max itemId: 1682\n",
      "min itemId: 1\n",
      "    \n",
      "y set:  {0, 1, 2, 3, 4}\n",
      "\n",
      "    type: test \n",
      "=============================\n",
      "num user: 459\n",
      "max userId: 462\n",
      "\n",
      "num item: 1410\n",
      "max itemId: 1591\n",
      "min itemId: 1\n",
      "    \n",
      "y set:  {0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "traindir = 'MovieLens/u1.base' \n",
    "testdir ='MovieLens/u1.test'\n",
    "\n",
    "x_train,y_train = load_data(traindir)\n",
    "x_test ,y_test = load_data(testdir)\n",
    "\n",
    "max_u , max_i, max_y = meta(x_train,  y_train)\n",
    "tmp_u , tmp_i, tmp_y = meta(x_test, y_test , 'test')\n",
    "max_u = max(max_u , tmp_u)\n",
    "max_i = max(max_i , tmp_i)\n",
    "max_y = max(max_y , tmp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suspended-preparation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 128)       120960      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 128)       215552      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 1, 256)       0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 128)       32896       tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64)        8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1)         65          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 377,729\n",
      "Trainable params: 377,729\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(max_u= max_u+1 , max_i = max_i+1 , max_y=max_y+1 ):\n",
    "    input_u = Input(shape=(1,))\n",
    "    input_i = Input(shape=(1,))\n",
    "    \n",
    "    emb_user = Embedding(max_u+1 , 128)\n",
    "    emb_item = Embedding(max_i+1 , 128)\n",
    "    linear = Dense( 128, activation='relu')\n",
    "    linear2 = Dense( 64, activation='relu')\n",
    "#     logit = Dense(max_y, activation= 'softmax')\n",
    "    logit = Dense(1)\n",
    "#     output  = Dense(1 )\n",
    "    \n",
    "    latent_u = emb_user(input_u)\n",
    "    latent_i = emb_item(input_i)\n",
    "    latent = tf.concat([latent_u , latent_i] , axis=-1)\n",
    "    latent = linear(latent)\n",
    "    latent = linear2(latent)\n",
    "    output = logit(latent)\n",
    "#     output\n",
    "    model = Model(inputs = [input_u , input_i] , outputs = output)\n",
    "    model.summary()\n",
    "    return model\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "geographic-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(\n",
    "#     filepath='.',\n",
    "#     save_weights_only=True,\n",
    "#     monitor='val_loss',\n",
    "#     mode='min',\n",
    "#     save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          patience = 2 , \n",
    "                          mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "clean-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen\n",
    "# so far.\n",
    "model.compile(loss = 'mse',\n",
    "             optimizer='adam',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gentle-stream",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "2500/2500 - 4s - loss: 1.0259 - acc: 0.1152 - val_loss: 0.9246 - val_acc: 0.1155\n",
      "Epoch 2/2000\n",
      "2500/2500 - 4s - loss: 0.8734 - acc: 0.1172 - val_loss: 0.9254 - val_acc: 0.1166\n",
      "Epoch 3/2000\n",
      "2500/2500 - 4s - loss: 0.8332 - acc: 0.1190 - val_loss: 0.8976 - val_acc: 0.1138\n",
      "Epoch 4/2000\n",
      "2500/2500 - 4s - loss: 0.7763 - acc: 0.1208 - val_loss: 0.8973 - val_acc: 0.1151\n",
      "Epoch 5/2000\n",
      "2500/2500 - 3s - loss: 0.7043 - acc: 0.1230 - val_loss: 0.9031 - val_acc: 0.1195\n",
      "Epoch 6/2000\n",
      "2500/2500 - 3s - loss: 0.6286 - acc: 0.1253 - val_loss: 0.9357 - val_acc: 0.1175\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,\n",
    "          y=y_train ,\n",
    "          validation_data = (x_test , y_test),\n",
    "          epochs = 2000 , batch_size= 32 , verbose = 2,\n",
    "         callbacks=[ earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-fetish",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discretize = lambda x: np.floor(x+.5)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "# y_pred =np.argmax(y_pred.reshape(-1,5) , axis = -1)\n",
    "y_pred = discretize(y_pred)\n",
    "rmse = mse( y_test , y_pred , squared = False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "regional-monkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3.])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor([.5 ,3.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-wildlife",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
